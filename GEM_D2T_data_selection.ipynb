{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille-s/GEM24_D2T_StratifiedSampling/blob/main/GEM_D2T_data_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hyry7e09e7P"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import csv\n",
        "import random\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WudT_LOiIoN"
      },
      "outputs": [],
      "source": [
        "# filepath definition\n",
        "\n",
        "# project_dir_path = os.path.join('/', 'content', 'drive', 'MyDrive', 'WebNLG_data_selection')\n",
        "project_dir_path = '/content'\n",
        "rdf_path = os.path.join(project_dir_path, 'testdata')\n",
        "output_path = os.path.join(rdf_path, 'output_data.csv')\n",
        "\n",
        "if not os.path.exists(rdf_path):\n",
        "  os.makedirs(rdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhuUak3C3Arj"
      },
      "outputs": [],
      "source": [
        "seed = 49"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfOxH6Hr9kcf"
      },
      "outputs": [],
      "source": [
        "def extract_data(rdf_filepath, stratify_categories, exclude_size):\n",
        "\n",
        "  '''\n",
        "      This method:\n",
        "      a. extracts the required entries (RDF triple(s), number of triples, property and category) from the json file.\n",
        "      b. categorizes the triple and verbalisation pair as seen/unseen category based on its presence in the training set.\n",
        "      c. groups the required extracted entry field (in this case, number of triples and property) for stratified selection.\n",
        "  '''\n",
        "\n",
        "  data = []\n",
        "  count = 0\n",
        "  for filename in os.listdir(rdf_filepath):\n",
        "    tree = ET.parse(f\"{rdf_filepath}/{filename}\")\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # extract triples\n",
        "    for entry in root.findall('./entries/entry'):\n",
        "      triples = []\n",
        "      pred = []\n",
        "      for triple in entry.find('modifiedtripleset').findall('mtriple'):\n",
        "        str_triple = triple.text\n",
        "        triples.append(str_triple)\n",
        "        only_pred = str_triple.split('|')[1]\n",
        "        pred.append(only_pred)\n",
        "      if exclude_size == 'none' or (exclude_size == '1 only' and int(entry.attrib['size']) > 1) or (exclude_size == '1 and 2' and int(entry.attrib['size']) > 2):\n",
        "        curr_entry = {\n",
        "            'id': count,\n",
        "            'triples': triples.copy(),\n",
        "            'property': pred.copy(),\n",
        "            'num_triples': int(entry.attrib['size']),\n",
        "            'category': 'unseen' if entry.attrib['category'] in ['Athlete', 'Artist', 'CelestialBody', 'MeanOfTransportation', 'Politician'] else 'seen',\n",
        "            'category_all': entry.attrib['category']\n",
        "        }\n",
        "        if stratify_categories == 'seenUnseen':\n",
        "          curr_entry['strat_field'] = str(curr_entry['num_triples'])+curr_entry['category']\n",
        "        elif stratify_categories == 'allCategories':\n",
        "          curr_entry['strat_field'] = str(curr_entry['num_triples'])+curr_entry['category_all']\n",
        "        data.append(curr_entry)\n",
        "        count += 1\n",
        "\n",
        "  # Remove data points for which there is only one member in a stratify category (triggers an error when stratifying, needs 2 members min)\n",
        "  clean_data = []\n",
        "  # Make a dico with the count of instances of each strat_field\n",
        "  count_strat_field_instances = {}\n",
        "  for datapoint in data:\n",
        "    if datapoint['strat_field'] in count_strat_field_instances:\n",
        "      count_strat_field_instances[datapoint['strat_field']] += 1\n",
        "    else:\n",
        "      count_strat_field_instances[datapoint['strat_field']] = 1\n",
        "  # If a count of a strat_field is one, do no include it in the final dataset\n",
        "  for datapoint_clean in data:\n",
        "    if count_strat_field_instances[datapoint_clean['strat_field']] == 1:\n",
        "      print(f\"  Removed datapoint  {datapoint_clean['strat_field']} because there is only one member!\")\n",
        "    else:\n",
        "      clean_data.append(datapoint_clean)\n",
        "\n",
        "  return clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8idE1moVjJL3"
      },
      "outputs": [],
      "source": [
        "stratify_categories = 'allCategories'#@param['seenUnseen', 'allCategories']\n",
        "number_samples = \"180\"#@param[50, 100, 120, 150, 180, 200, 300, 400, 500]\n",
        "num_samples = int(number_samples)\n",
        "exclude_size = '1 only'#@param['none', '1 only', '1 and 2']\n",
        "# Get data\n",
        "data=extract_data(rdf_path, stratify_categories, exclude_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN3pAE5N-ti-"
      },
      "outputs": [],
      "source": [
        "# stratified selection using train_test_split\n",
        "\n",
        "tset = pd.DataFrame.from_dict(data)\n",
        "X_train, X_test, = train_test_split(tset, test_size=num_samples, random_state=seed, stratify=tset['strat_field'], shuffle=True)\n",
        "print(len(X_train), len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tset['num_triples']\n",
        "# len(tset.loc[tset['category'] == 'unseen'])\n",
        "# print(X_test['num_triples'])\n",
        "\n",
        "# Show mean of column that contains triple number in each input (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html)\n",
        "# print(X_test.loc[:, 'num_triples'].mean())\n",
        "print(f\"{round(X_test['num_triples'].mean(), 2)} triples per input on average\")\n",
        "\n",
        "def count_num_instances(pd_column):\n",
        "  count = {}\n",
        "  for category in pd_column:\n",
        "    if category in count:\n",
        "      count[category] += 1\n",
        "    else:\n",
        "      count[category] = 1\n",
        "\n",
        "  for count_category in sorted(count):\n",
        "    print(f'{count_category}\\t{count[count_category]}')\n",
        "    # print(f'{count[count_category]}')\n",
        "  print('-----------------')\n",
        "\n",
        "count_num_instances(X_test['num_triples'])\n",
        "count_num_instances(X_test['category_all'])"
      ],
      "metadata": {
        "id": "wT8jGcydF28v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoBNN96VZEQp"
      },
      "outputs": [],
      "source": [
        "X_test.to_csv(output_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}